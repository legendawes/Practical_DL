{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will build a monster network to solve Tiny ImageNet image classification.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +10% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 25% (50% points)\n",
    "    * 30% (60% points)\n",
    "    * 32.5% (70% points)\n",
    "    * 35% (80% points)\n",
    "    * 37.5% (90% points)\n",
    "    * 40% (full points)\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 40%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the anytask atttachments). After that, you can use whatever you want.\n",
    "* you __can't__ do anything with validation data apart from running the evaluation procedure. Please, split train images on train and validation parts\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.ImageFolder(root=path_to_tiny_imagenet, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  6 20:32:14 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 4000     On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8     9W / 125W |   1081MiB /  7982MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 4000     On   | 00000000:05:00.0 Off |                  N/A |\n",
      "| 30%   56C    P0    42W / 125W |    803MiB /  7982MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 4000     On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8     8W / 125W |     12MiB /  7982MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 4000     On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 30%   59C    P0   123W / 125W |   4757MiB /  7982MiB |     69%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 4000     On   | 00000000:84:00.0 Off |                  N/A |\n",
      "| 30%   26C    P8     4W / 125W |    807MiB /  7982MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 4000     On   | 00000000:85:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8     7W / 125W |     12MiB /  7982MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     21731      C   /usr/bin/python3                            1069MiB |\n",
      "|    1     14062      C   /usr/bin/python3                             791MiB |\n",
      "|    3     15710      C   /usr/bin/python3                            4745MiB |\n",
      "|    4     43179      C   /usr/bin/python3                             795MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# %load ~/gpu_imports.py\n",
    "# run %load ~/gpu_imports.py in cell and enjoy the magic\n",
    "!nvidia-smi\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path('/data/iagolovanov')\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_img import download_tinyImg200\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# download_tinyImg200(DATA_PATH) #untars in the current directory anyway\n",
    "# !mv tiny-imagenet-200 $DATA_PATH\n",
    "dataset = torchvision.datasets.ImageFolder(DATA_PATH / 'tiny-imagenet-200/train',\n",
    "                                           transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.ImageFolder(DATA_PATH / 'tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])\n",
    "test_dataset, val_dataset = torch.utils.data.random_split(val_dataset, [10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=1)\n",
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X_batch, y_batch) in train_batch_gen:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_channels, width, height = X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (8): Flatten()\n",
       "  (9): Linear(in_features=10368, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empiric rule - amount of output channels approximately equals number of classes\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=n_channels, out_channels=64, kernel_size=(3,3)),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    \n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=3),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(10368, 200)\n",
    "                     )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = X_batch.cuda()\n",
    "    y_batch = y_batch.cuda()\n",
    "    logits = model.cuda()(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# train_loss = []\n",
    "# val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50 took 109.551s\n",
      "  training loss (in-iteration): \t4.544943\n",
      "  validation accuracy: \t\t\t15.02 %\n",
      "Epoch 2 of 50 took 41.674s\n",
      "  training loss (in-iteration): \t3.553562\n",
      "  validation accuracy: \t\t\t18.81 %\n",
      "Epoch 3 of 50 took 48.116s\n",
      "  training loss (in-iteration): \t3.017257\n",
      "  validation accuracy: \t\t\t19.53 %\n",
      "Epoch 4 of 50 took 62.288s\n",
      "  training loss (in-iteration): \t2.578117\n",
      "  validation accuracy: \t\t\t20.57 %\n",
      "Epoch 5 of 50 took 43.497s\n",
      "  training loss (in-iteration): \t2.105315\n",
      "  validation accuracy: \t\t\t19.28 %\n",
      "Epoch 6 of 50 took 76.693s\n",
      "  training loss (in-iteration): \t1.582942\n",
      "  validation accuracy: \t\t\t19.52 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "num_epochs = 50 # total amount of full passes over training data\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in train_batch_gen:\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "    \n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_batch_gen:\n",
    "        logits = model(X_batch.cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    train_l = np.mean(train_loss[-len(train_dataset) // batch_size :])\n",
    "    val_acc = np.mean(val_accuracy[-len(test_dataset) // batch_size :]) * 100\n",
    "    # Then we print the results for this epoch:\n",
    "    print(f\"Epoch {epoch + 1} of {num_epochs} took {epoch_time:.3f}s\")\n",
    "    print(f\"  training loss (in-iteration): \\t{train_l:.6f}\")\n",
    "    print(f\"  validation accuracy: \\t\\t\\t{val_acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything is done, please calculate accuracy on `tiny-imagenet-200/val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = .... # YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 35:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 25:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `___ ___`, and here's my story\n",
    "\n",
    "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, i got an idea:\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "* brief text on what was\n",
    "* the original idea\n",
    "* and why it was so\n",
    "\n",
    "How could i be so naive?!\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "This thing has finally converged and\n",
    "* Some explaination about what were the results,\n",
    "* what worked and what didn't\n",
    "* most importantly - what next steps were taken, if any\n",
    "* and what were their respective outcomes\n",
    "\n",
    "##### Finally, after __  iterations, __ mugs of [tea/coffee]\n",
    "* what was the final architecture\n",
    "* as well as training method and tricks\n",
    "\n",
    "That, having wasted ____ [minutes, hours or days] of my life training, got\n",
    "\n",
    "* accuracy on training: __\n",
    "* accuracy on validation: __\n",
    "* accuracy on test: __\n",
    "\n",
    "\n",
    "[an optional afterword and mortal curses on assignment authors]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
